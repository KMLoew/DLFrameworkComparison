{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:  3.6.8\n",
      "tensorflow:  1.13.1\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "print('python: ', platform.python_version())\n",
    "print('tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "\n",
    "training_images, test_images, training_labels, test_labels = train_test_split(np.load('images.npy'), \n",
    "                                                                              np.load('labels.npy'), test_size=0.15)\n",
    "\n",
    "np.save('test_images',test_images)\n",
    "np.save('test_labels',test_labels)\n",
    "\n",
    "np.save('training_images',training_images)\n",
    "np.save('training_labels',training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550, 150, 150, 3)\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "myShape=(training_images.shape)\n",
    "print(myShape)\n",
    "print(np.amax(training_images))\n",
    "print(np.amin(training_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kloew/anaconda3/envs/IntelImages/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 75, 75, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 19, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 19, 19, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 19, 19, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 12294     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 7,888,454\n",
      "Trainable params: 7,882,566\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(7, 7),strides=2,padding='same',input_shape=myShape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv2D(256, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(256, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(256, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3, 3),strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv2D(512, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(512, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(512, kernel_size=(3, 3), padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten(input_shape=(None,myShape[0],myShape[1])))\n",
    "model.add(Dense(len(classes)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myOpt=keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2550 samples, validate on 450 samples\n",
      "Epoch 1/15\n",
      "2550/2550 [==============================] - 68s 27ms/sample - loss: 1.8585 - acc: 0.3647 - val_loss: 7.2968 - val_acc: 0.2044\n",
      "Epoch 2/15\n",
      "2240/2550 [=========================>....] - ETA: 7s - loss: 1.1850 - acc: 0.5129"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_images, training_labels, epochs=15, verbose=1,\n",
    "                   validation_data=(test_images, test_labels) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2,figsize=(10,10))\n",
    "#f.suptitle('Comparing the Images')\n",
    "ax1.plot(history.history['acc'],'r',label='Training Accuracy')\n",
    "ax1.plot(history.history['val_acc'],'b',label='Validation Accuracy')\n",
    "ax1.legend()\n",
    "ax1.xlabel('Epochs ')\n",
    "ax1.ylabel('Accuracy')\n",
    "ax1.title('Accuracy Curves')\n",
    "\n",
    "ax2.plot(history.history['loss'],'r',label='Training loss')\n",
    "ax2.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "ax2.legend()\n",
    "ax2.xlabel('Epochs ')\n",
    "ax2.ylabel('Loss')\n",
    "ax2.title('Loss Curves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
