{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:  3.6.8\n",
      "tensorflow:  1.13.1\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "print('python: ', platform.python_version())\n",
    "print('tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "\n",
    "training_images, test_images, training_labels, test_labels = train_test_split(np.load('images.npy'), \n",
    "                                                                              np.load('labels.npy'), test_size=0.15)\n",
    "\n",
    "np.save('test_images',test_images)\n",
    "np.save('test_labels',test_labels)\n",
    "\n",
    "np.save('training_images',training_images)\n",
    "np.save('training_labels',training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550, 150, 150, 3)\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "myShape=(training_images.shape)\n",
    "print(myShape)\n",
    "print(np.amax(training_images))\n",
    "print(np.amin(training_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kloew/anaconda3/envs/IntelImages/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 148, 148, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 148, 148, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 74, 74, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 74, 74, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 74, 74, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 74, 74, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 72, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 36, 36, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 36, 36, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 34, 34, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 34, 34, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 17, 17, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 17, 17, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 15, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 10,971,782\n",
      "Trainable params: 10,964,102\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding='same',activation='relu',input_shape=myShape[1:]))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(512, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(512, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Conv2D(512, kernel_size=(3, 3),activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Flatten(input_shape=(None,myShape[0],myShape[1])))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myOpt=keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=myOpt, loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2550 samples, validate on 450 samples\n",
      "WARNING:tensorflow:From /home/kloew/anaconda3/envs/IntelImages/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "2550/2550 [==============================] - 233s 91ms/sample - loss: 2.2025 - acc: 0.4294 - val_loss: 1.2878 - val_acc: 0.5111\n",
      "Epoch 2/30\n",
      "2550/2550 [==============================] - 231s 90ms/sample - loss: 1.1379 - acc: 0.5580 - val_loss: 1.1429 - val_acc: 0.6067\n",
      "Epoch 3/30\n",
      "2550/2550 [==============================] - 232s 91ms/sample - loss: 0.9674 - acc: 0.6318 - val_loss: 1.0755 - val_acc: 0.6089\n",
      "Epoch 4/30\n",
      "2550/2550 [==============================] - 231s 91ms/sample - loss: 0.9002 - acc: 0.6686 - val_loss: 1.0613 - val_acc: 0.6444\n",
      "Epoch 5/30\n",
      "2550/2550 [==============================] - 231s 91ms/sample - loss: 0.8406 - acc: 0.6957 - val_loss: 0.8478 - val_acc: 0.7133\n",
      "Epoch 6/30\n",
      "2550/2550 [==============================] - 231s 91ms/sample - loss: 0.7218 - acc: 0.7302 - val_loss: 0.9369 - val_acc: 0.6756\n",
      "Epoch 7/30\n",
      "2550/2550 [==============================] - 231s 91ms/sample - loss: 0.7038 - acc: 0.7404 - val_loss: 0.9619 - val_acc: 0.6956\n",
      "Epoch 8/30\n",
      "2550/2550 [==============================] - 239s 94ms/sample - loss: 0.7107 - acc: 0.7455 - val_loss: 0.7775 - val_acc: 0.7222\n",
      "Epoch 9/30\n",
      "2550/2550 [==============================] - 233s 91ms/sample - loss: 0.6545 - acc: 0.7737 - val_loss: 0.6771 - val_acc: 0.7667\n",
      "Epoch 10/30\n",
      "2550/2550 [==============================] - 238s 93ms/sample - loss: 0.6505 - acc: 0.7737 - val_loss: 0.6033 - val_acc: 0.7756\n",
      "Epoch 11/30\n",
      "2550/2550 [==============================] - 256s 100ms/sample - loss: 0.5593 - acc: 0.8035 - val_loss: 0.6576 - val_acc: 0.7511\n",
      "Epoch 12/30\n",
      "  64/2550 [..............................] - ETA: 3:59 - loss: 0.3989 - acc: 0.8438"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_images, training_labels, epochs=30, verbose=1,\n",
    "                   validation_data=(test_images, test_labels) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2,figsize=(10,5))\n",
    "#f.suptitle('Comparing the Images')\n",
    "ax1.plot(history.history['acc'],'r',label='Training Accuracy')\n",
    "ax1.plot(history.history['val_acc'],'b',label='Validation Accuracy')\n",
    "ax1.legend()\n",
    "ax1.set(xlabel='Epochs', ylabel='Accuracy')\n",
    "\n",
    "ax2.plot(history.history['loss'],'r',label='Training loss')\n",
    "ax2.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "ax2.legend()\n",
    "ax.set(xlabel='Epochs', ylabel='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
