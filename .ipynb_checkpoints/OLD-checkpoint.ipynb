{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:  3.6.8\n",
      "tensorflow:  1.13.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "print('python: ', platform.python_version())\n",
    "print('tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = 'seg_train'\n",
    "test_path = 'seg_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_class = {}\n",
    "for i in os.listdir(training_path):\n",
    "    training_class[i] =  os.listdir(training_path+'/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "class_list = []\n",
    "classes = []\n",
    "dr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in training_class:\n",
    "    classes.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii,val in enumerate(training_class.values()):\n",
    "    for img in val :\n",
    "        img_list.append(img)\n",
    "        class_list.append(classes[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(class_list)):\n",
    "    dr.append(training_path+'/'+class_list[ii]+'/'+img_list[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator=ImageDataGenerator(rescale=1.0/255,rotation_range=45,horizontal_flip=True,vertical_flip=True)\n",
    "\n",
    "test_data_generator=ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 images belonging to 196 classes.\n",
      "Found 8041 images belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_data_generator.flow_from_directory(training_path,target_size = (150,150),\n",
    "                                                         batch_size = 64,class_mode='sparse')\n",
    "\n",
    "test_generator=test_data_generator.flow_from_directory(test_path,target_size=(150,150),\n",
    "                                                       batch_size=64,class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in function len>\n"
     ]
    }
   ],
   "source": [
    "batch_size=64 \n",
    "num_train_images=8144\n",
    "print(len)\n",
    "\n",
    "myOpt=keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer=myOpt, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "filepath='ResNet50_weights1.h5'\n",
    "checkpoint=ModelCheckpoint(filepath,monitor=['acc'],verbose=1,mode='max')\n",
    "callbacks_list=[checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 [==============================] - 476s 4s/step - loss: 14.9480 - acc: 0.0058\n",
      "\n",
      "Epoch 00001: saving model to ResNet50_weights1.h5\n",
      "128/128 [==============================] - 4503s 35s/step - loss: 14.9836 - acc: 0.0060 - val_loss: 14.9480 - val_acc: 0.0058\n",
      "Epoch 2/10\n",
      "  3/128 [..............................] - ETA: 1:09:42 - loss: 14.8342 - acc: 0.0104"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(train_generator,epochs=10,steps_per_epoch=num_train_images//batch_size,\n",
    "                            shuffle=True,callbacks=callbacks_list,\n",
    "                            validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curves\n",
    "f,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "ax1.plot(history.history['acc'],'r',label='Training Accuracy')\n",
    "ax1.plot(history.history['val_acc'],'b',label='Validation Accuracy')\n",
    "ax1.set(xlabel='Epochs',ylabel='Accuracy')\n",
    "\n",
    "ax2.plot(history.history['loss'],'r',label='Training Loss')\n",
    "ax2.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "ax2.set(xlabel='Epochs',ylabel='Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
